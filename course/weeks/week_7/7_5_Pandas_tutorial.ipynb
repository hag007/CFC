{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7db204bd",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>\n",
       "(function() {\n",
       "  // Create the toggle button\n",
       "  const rtlButton = document.createElement(\"button\");\n",
       "  rtlButton.textContent = \"Toggle LTR\";\n",
       "  rtlButton.id = \"top-rtl-toggle\";\n",
       "  rtlButton.style.marginLeft = \"8px\";\n",
       "  rtlButton.style.padding = \"4px 10px\";\n",
       "  rtlButton.style.fontSize = \"14px\";\n",
       "  rtlButton.style.cursor = \"pointer\";\n",
       "\n",
       "  // State\n",
       "  var rtlActive = false;\n",
       "\n",
       "  // Styling function\n",
       "  var applyStyleToEditor = (editor) => {\n",
       "    if (!editor) return;\n",
       "    var direction = getComputedStyle(editor).getPropertyValue('direction')=='rtl' ? 'ltr' : 'rtl';\n",
       "    var text_align = getComputedStyle(editor).getPropertyValue('text-align')=='right' ? 'left' : 'right';\n",
       "    editor.style.setProperty('direction', direction, 'important');\n",
       "    editor.style.setProperty('text-align', text_align, 'important');\n",
       "  };\n",
       "\n",
       "  // Toggle logic\n",
       "  rtlButton.onclick = () => {\n",
       "    rtlActive = !rtlActive;\n",
       "    rtlButton.textContent = rtlActive ? \"Toggle LTR\" : \"Toggle RTL\";\n",
       "    document.querySelectorAll('.jp-MarkdownCell .jp-InputArea-editor').forEach(applyStyleToEditor);\n",
       "    document.querySelectorAll('.jp-RenderedHTMLCommon code, .jp-RenderedHTMLCommon code span').forEach(applyStyleToEditor);\n",
       "    document.querySelectorAll('jp-RenderedHTMLCommon, .jp-RenderedHTMLCommon *').forEach(applyStyleToEditor);\n",
       "  };\n",
       "\n",
       "  // Watch for focus into editing Markdown cells\n",
       "  // document.addEventListener('focusin', (event) => {\n",
       "  //   const editor = event.target.closest('.jp-MarkdownCell .jp-InputArea-editor');\n",
       "  //    if (editor) applyStyleToEditor(editor);\n",
       "  // });\n",
       "\n",
       "  // Insert into top toolbar if not already present\n",
       "  var insertIntoToolbar = () => {\n",
       "    const toolbar = document.querySelector('.jp-NotebookPanel-toolbar');\n",
       "    if (toolbar && !document.getElementById(\"top-rtl-toggle\")) {\n",
       "      toolbar.appendChild(rtlButton);\n",
       "    } else {\n",
       "      // Try again in a moment if toolbar isn't ready yet\n",
       "      setTimeout(insertIntoToolbar, 300);\n",
       "    }\n",
       "  };\n",
       "\n",
       "  insertIntoToolbar();\n",
       "})();\n",
       "</script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<script>\n",
    "(function() {\n",
    "  // Create the toggle button\n",
    "  const rtlButton = document.createElement(\"button\");\n",
    "  rtlButton.textContent = \"Toggle LTR\";\n",
    "  rtlButton.id = \"top-rtl-toggle\";\n",
    "  rtlButton.style.marginLeft = \"8px\";\n",
    "  rtlButton.style.padding = \"4px 10px\";\n",
    "  rtlButton.style.fontSize = \"14px\";\n",
    "  rtlButton.style.cursor = \"pointer\";\n",
    "\n",
    "  // State\n",
    "  var rtlActive = false;\n",
    "\n",
    "  // Styling function\n",
    "  var applyStyleToEditor = (editor) => {\n",
    "    if (!editor) return;\n",
    "    var direction = getComputedStyle(editor).getPropertyValue('direction')=='rtl' ? 'ltr' : 'rtl';\n",
    "    var text_align = getComputedStyle(editor).getPropertyValue('text-align')=='right' ? 'left' : 'right';\n",
    "    editor.style.setProperty('direction', direction, 'important');\n",
    "    editor.style.setProperty('text-align', text_align, 'important');\n",
    "  };\n",
    "\n",
    "  // Toggle logic\n",
    "  rtlButton.onclick = () => {\n",
    "    rtlActive = !rtlActive;\n",
    "    rtlButton.textContent = rtlActive ? \"Toggle LTR\" : \"Toggle RTL\";\n",
    "    document.querySelectorAll('.jp-MarkdownCell .jp-InputArea-editor').forEach(applyStyleToEditor);\n",
    "    document.querySelectorAll('.jp-RenderedHTMLCommon code, .jp-RenderedHTMLCommon code span').forEach(applyStyleToEditor);\n",
    "    document.querySelectorAll('jp-RenderedHTMLCommon, .jp-RenderedHTMLCommon *').forEach(applyStyleToEditor);\n",
    "  };\n",
    "\n",
    "  // Watch for focus into editing Markdown cells\n",
    "  // document.addEventListener('focusin', (event) => {\n",
    "  //   const editor = event.target.closest('.jp-MarkdownCell .jp-InputArea-editor');\n",
    "  //    if (editor) applyStyleToEditor(editor);\n",
    "  // });\n",
    "\n",
    "  // Insert into top toolbar if not already present\n",
    "  var insertIntoToolbar = () => {\n",
    "    const toolbar = document.querySelector('.jp-NotebookPanel-toolbar');\n",
    "    if (toolbar && !document.getElementById(\"top-rtl-toggle\")) {\n",
    "      toolbar.appendChild(rtlButton);\n",
    "    } else {\n",
    "      // Try again in a moment if toolbar isn't ready yet\n",
    "      setTimeout(insertIntoToolbar, 300);\n",
    "    }\n",
    "  };\n",
    "\n",
    "  insertIntoToolbar();\n",
    "})();\n",
    "</script>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "87c1f76a",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<!-- <style>\n",
       "  table {display: inline-block}\n",
       "</style> -->\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<!-- <style>\n",
    "  table {display: inline-block}\n",
    "</style> -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8717ec",
   "metadata": {},
   "source": [
    "# תרגיל: דוח תפעול יומי למערך גלאים\n",
    "\n",
    "בתרגיל הזה נתרגל עבודה עם **Pandas** דרך סימולציה של מצב אמיתי מעולמות הפיזיקה הניסויית:  \n",
    "מערך גלאים (למשל קרינה/קרניים קוסמיות) שמייצר **לוג אירועים** לאורך זמן, ובמקביל מערכת ניטור סביבתי שמודדת **טמפרטורה** מכמה פרובים.\n",
    "\n",
    "המטרה שלנו היא לקחת נתונים “גולמיים” (Raw Logs) — שכוללים לפעמים **טיימסטמפים לא תקינים**, **ערכים חסרים**, וסדר לא מסודר — ולהפיק מהם **דוח יומי** נקי ושמיש.\n",
    "\n",
    "במהלך התרגיל תתרגלו:\n",
    "\n",
    "- **ניקוי נתונים (Data Cleaning)**  \n",
    "  המרת עמודת זמן למבנה datetime עם `pd.to_datetime(..., errors=\"coerce\")`, סילוק שורות בעייתיות, וטיפול בערכים חסרים.\n",
    "\n",
    "- **עבודה עם תאריכים וזמן (Date/Time)**  \n",
    "  חילוץ תאריך יומי מתוך timestamp (לצורך סיכום לפי ימים).\n",
    "\n",
    "- **Pivot Tables**  \n",
    "  יצירת טבלת דוח רחבה של *טמפרטורה ממוצעת לפי יום ולפי פרוב* בעזרת `pivot_table`.\n",
    "\n",
    "- **GroupBy + size + unstack**  \n",
    "  ספירת מספר אירועים לפי יום ולפי גלאי, והפיכת התוצאה לטבלה רחבה שמתאימה לדוח.\n",
    "\n",
    "- **Merge / Join (מתקדם)**  \n",
    "  חיבור לוג האירועים לטבלת מטא-דאטה של גלאים (קליברציה), כדי להמיר מדידה גולמית לערך פיזיקלי “מחושב”.\n",
    "\n",
    "- **טרנספורמציות ועמודות נגזרות (Vectorized transforms)**  \n",
    "  חישוב אנרגיה מכוילת לכל אירוע בצורה וקטורית (ללא לולאות).\n",
    "\n",
    "- **שינויי מבנה (Reshaping)**  \n",
    "  מעבר בין פורמט רחב לפורמט ארוך (`melt`) לצורך גרפים/ניתוחים.\n",
    "\n",
    "- **ויזואליזציה מהירה**  \n",
    "  גרפים בסיסיים של ספירות אירועים וטמפרטורות לאורך זמן.\n",
    "\n",
    "התרגיל מדמה Workflow נפוץ במעבדה:\n",
    "1. קבלת לוגים ממכשור מדידה (אירועים + סביבה)\n",
    "2. ניקוי ותיקון נתונים\n",
    "3. סיכום יומי לפי חיישנים/גלאים\n",
    "4. שילוב נתוני קליברציה/מטא-דאטה\n",
    "5. הפקת דוח תפעולי שמאפשר לזהות תקלות, חריגות ועקביות לאורך זמן\n",
    "\n",
    "בסוף התרגיל יהיו לכם כמה “טבלאות דוח” מרכזיות + גרפים קצרים — בדיוק כמו בדוח ניטור יומי של מערכת מדידה אמיתית.\n",
    "\n",
    "## חלק 0 – יצירת נתוני ניסוי\n",
    "\n",
    "קטע הקוד יוצר **סט נתונים סינתטי** המדמה לוגים של ניסוי פיזיקלי אמיתי, עם דגש על ריאליזם ולא על “נתונים נקיים”.\n",
    "\n",
    "נטענות ספריות העבודה הסטנדרטיות, ומאותחל מחולל מספרים אקראיים עם seed קבוע לצורך שחזור תוצאות.\n",
    "\n",
    "נבנית טבלת מטא-דאטה של גלאים, הכוללת שיוך למודולים ופרמטרי קליברציה (gain, offset), כפי שמקובל במערכות מדידה אמיתיות.\n",
    "\n",
    "לאחר מכן נוצר לוג אירועים:\n",
    "אירועים מתרחשים בזמנים אקראיים ולא אחידים לאורך כמה ימים, לכל אירוע משויכים גלאי וערך מדידה גולמי (ADC) עם רעש.\n",
    "\n",
    "בכוונה מוכנסים לנתונים:\n",
    "- חותמות זמן לא תקינות  \n",
    "- ערכי מדידה חסרים  \n",
    "\n",
    "בנוסף נוצר לוג נפרד של מדידות טמפרטורה מכמה פרובים סביבתיים, גם הוא כולל רעש, ערכים חסרים וחותמות זמן שגויות.\n",
    "\n",
    "לבסוף מודפסים גדלי הטבלאות כדי לקבל תמונת מצב ראשונית על היקף הנתונים לפני שלב הניקוי והעיבוד.\n",
    "\n",
    "הקטע כולו מדמה נקודת התחלה של ניתוח נתונים ניסויי, שעליה נבצע בהמשך ניקוי, סיכום וניתוח באמצעות Pandas.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7db8b867",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw shapes:\n",
      "  detectors: (6, 4)\n",
      "  events: (3500, 3)\n",
      "  temps: (1400, 3)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# -----------------------------\n",
    "# 0) Generate synthetic-but-realistic data (raw, slightly messy)\n",
    "# -----------------------------\n",
    "rng = np.random.default_rng(42)\n",
    "\n",
    "# Detector metadata / calibration\n",
    "detectors = pd.DataFrame({\n",
    "    \"detector\": [f\"D{i}\" for i in range(1, 7)],\n",
    "    \"module\":   [\"M1\", \"M1\", \"M2\", \"M2\", \"M3\", \"M3\"],\n",
    "    \"gain\":     rng.uniform(0.8, 1.4, size=6),\n",
    "    \"offset\":   rng.uniform(-5.0, 5.0, size=6),\n",
    "})\n",
    "\n",
    "# Create a time range spanning multiple days, but events are irregular\n",
    "start = pd.Timestamp(\"2025-12-20 00:00:00\")\n",
    "end   = pd.Timestamp(\"2025-12-26 23:59:59\")\n",
    "total_seconds = int((end - start).total_seconds())\n",
    "\n",
    "n_events = 3500\n",
    "event_times = start + pd.to_timedelta(rng.integers(0, total_seconds, size=n_events), unit=\"s\")\n",
    "event_times = pd.Series(event_times).sample(frac=1, random_state=0).reset_index(drop=True)  # shuffled\n",
    "\n",
    "events = pd.DataFrame({\n",
    "    \"timestamp\": event_times.astype(str),  # stored as strings in raw logs\n",
    "    \"detector\": rng.choice(detectors[\"detector\"], size=n_events, replace=True),\n",
    "    \"adc\": rng.gamma(shape=4.0, scale=35.0, size=n_events) + rng.normal(0, 3, size=n_events),\n",
    "})\n",
    "\n",
    "# Add some deliberately invalid timestamps and a couple junk rows\n",
    "bad_idx = rng.choice(events.index, size=25, replace=False)\n",
    "events.loc[bad_idx, \"timestamp\"] = rng.choice(\n",
    "    [\"not_a_time\", \"2025-13-99 99:99:99\", \"\", \"2025/12/25 25:61:00\"],\n",
    "    size=len(bad_idx),\n",
    ")\n",
    "# Also introduce some missing adc values\n",
    "events.loc[rng.choice(events.index, size=15, replace=False), \"adc\"] = np.nan\n",
    "\n",
    "# Temperature probe logs (more regular, but still messy)\n",
    "probes = [\"T1\", \"T2\", \"T3\"]\n",
    "n_temps = 1400\n",
    "temp_times = start + pd.to_timedelta(rng.integers(0, total_seconds, size=n_temps), unit=\"s\")\n",
    "\n",
    "temps = pd.DataFrame({\n",
    "    \"timestamp\": pd.Series(temp_times).astype(str),\n",
    "    \"probe\": rng.choice(probes, size=n_temps, replace=True),\n",
    "    \"temp_C\": rng.normal(loc=24.0, scale=1.7, size=n_temps),\n",
    "})\n",
    "\n",
    "# Add a few invalid timestamps and missing temps\n",
    "bad_idx_t = rng.choice(temps.index, size=12, replace=False)\n",
    "temps.loc[bad_idx_t, \"timestamp\"] = rng.choice([\"bad\", \"2025-12-XX 12:00:00\", \"\"], size=len(bad_idx_t))\n",
    "temps.loc[rng.choice(temps.index, size=10, replace=False), \"temp_C\"] = np.nan\n",
    "\n",
    "print(\"Raw shapes:\")\n",
    "print(\"  detectors:\", detectors.shape)\n",
    "print(\"  events:\", events.shape)\n",
    "print(\"  temps:\", temps.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4dd26f5",
   "metadata": {},
   "source": [
    "## חלק 1 – ניקוי נתוני האירועים והטמפרטורות\n",
    "\n",
    "בקטע הזה אנחנו יוצרים גרסאות “נקיות” של שתי הטבלאות (`events`, `temps`) כדי שיהיה אפשר לעבוד איתן בצורה אמינה:\n",
    "\n",
    "- קודם כל עושים `copy()` כדי לא לשנות את הנתונים הגולמיים.\n",
    "- ממירים את עמודת הזמן למבנה datetime בעזרת `pd.to_datetime`, כאשר `errors=\"coerce\"` הופך ערכים לא תקינים ל־`NaT` (כלומר “זמן חסר”).\n",
    "- מסירים שורות בעייתיות באמצעות `dropna`:  \n",
    "  בלוג האירועים מסירים שורות עם timestamp לא תקין או ערך `adc` חסר,  \n",
    "  ובלוג הטמפרטורות מסירים שורות עם timestamp לא תקין או `temp_C` חסר.\n",
    "- לבסוף מוסיפים עמודת `date` שמכילה רק את התאריך (בלי שעה), כדי לאפשר סיכומים יומיים (daily rollup) בהמשך.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d3fdebaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After cleaning:\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# 1) Clean + parse timestamps (core exam skill: pd.to_datetime, errors='coerce')\n",
    "# -----------------------------\n",
    "# TODO: Create a clean copy of the raw events table (do not modify the original)\n",
    "# events_clean = ...\n",
    "# TODO: Convert the timestamp column to datetime; invalid strings should become NaT\n",
    "# events_clean[\"timestamp\"] = ...\n",
    "# TODO: Drop rows with invalid timestamps (NaT)\n",
    "# events_clean = ...\n",
    "# TODO: Drop rows with missing ADC measurements\n",
    "# events_clean = ...\n",
    "# TODO: Extract the calendar date for daily aggregations\n",
    "# events_clean[\"date\"] = ...\n",
    "\n",
    "\n",
    "# TODO: Create a clean copy of the raw temperature table (do not modify the original)\n",
    "# temps_clean = ...\n",
    "# TODO: Convert the timestamp column to datetime; invalid strings should become NaT\n",
    "# temps_clean[\"timestamp\"] = ...\n",
    "# TODO: Drop rows with invalid timestamps (NaT)\n",
    "# temps_clean = ...\n",
    "# TODO: Drop rows with missing temperature measurements\n",
    "# temps_clean = ...\n",
    "# TODO: Extract the calendar date for daily aggregations\n",
    "# temps_clean[\"date\"] = ...\n",
    "\n",
    "try:\n",
    "    print(\"\\nAfter cleaning:\")\n",
    "    print(\"  events_clean:\", events_clean.shape)\n",
    "    print(\"  temps_clean:\", temps_clean.shape)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964751b3",
   "metadata": {},
   "source": [
    "## חלק 2 – טבלת טמפרטורה יומית לכל פרוב (Pivot Table)\n",
    "\n",
    "כאן אנחנו מסכמים את נתוני הטמפרטורה הנקיים לטבלת דוח “רחבה”:\n",
    "- כל שורה מייצגת **תאריך** (`date`)\n",
    "- כל עמודה מייצגת **פרוב טמפרטורה** (`probe`)\n",
    "- בתאים מופיעה **הטמפרטורה הממוצעת** לאותו יום ולאותו פרוב (`mean` על `temp_C`)\n",
    "\n",
    "הפעולה נעשית עם `pivot_table`, ואז אנחנו ממיינים את האינדקס (ימים) ואת העמודות (הפרובים) כדי לקבל טבלה מסודרת לקריאה. לבסוף מדפיסים דוגמה קצרה עם `head()`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5b92a873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Daily mean temperature (date x probe):\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# 2) Daily mean temperature per probe (exam skill: pivot_table)\n",
    "# -----------------------------\n",
    "\n",
    "# TODO: Create a pivot table (wide format) that summarizes the cleaned temperature logs.\n",
    "#       Input table: temps_clean with columns [\"timestamp\", \"probe\", \"temp_C\", \"date\"].\n",
    "#       We want a DAILY summary, so:\n",
    "#         - index should be \"date\"  -> each row is one calendar day\n",
    "#         - columns should be \"probe\" -> each column is one temperature sensor/probe (T1/T2/T3...)\n",
    "#         - values should be \"temp_C\" -> the numeric measurement we aggregate\n",
    "#         - aggfunc should be \"mean\"  -> average temperature per (day, probe)\n",
    "#       Result: a report-like table where you can quickly compare probes across days.\n",
    "# daily_mean_temp = ...\n",
    "\n",
    "# TODO: Sort the resulting report table for consistent, readable output.\n",
    "#       - sort_index() ensures dates are in chronological order (oldest -> newest).\n",
    "#       - sort_index(axis=1) ensures probe columns are in a consistent order (e.g., T1, T2, T3).\n",
    "#       Tip: You can either chain both sorts after pivot_table, or do them in two steps.\n",
    "# daily_mean_temp = ...\n",
    "\n",
    "try:\n",
    "    print(\"\\nDaily mean temperature (date x probe):\")\n",
    "    print(daily_mean_temp.head())\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76575051",
   "metadata": {},
   "source": [
    "## חלק 3 – ספירת אירועים יומית לכל גלאי (groupby + size + unstack)\n",
    "\n",
    "כאן אנחנו בונים טבלת דוח שמראה **כמה אירועים נמדדו בכל יום בכל גלאי**:\n",
    "\n",
    "- מבצעים `groupby` לפי שני מפתחות: `date` (יום) ו־`detector` (גלאי), כדי לחלק את האירועים לקבוצות לפי (יום, גלאי).\n",
    "- משתמשים ב־`size()` כדי לקבל **ספירה** של מספר השורות בכל קבוצה (כלומר מספר האירועים).\n",
    "- הופכים את התוצאה לטבלה רחבה בעזרת `unstack`:  \n",
    "  השורות יהיו תאריכים, העמודות יהיו גלאים, והתאים יהיו מספר האירועים.\n",
    "- `fill_value=0` מבטיח שאם ביום מסוים לא היו אירועים בגלאי מסוים, נקבל 0 ולא ערך חסר.\n",
    "- בסוף ממיינים את האינדקס (ימים) והעמודות (גלאים) לקבלת דוח מסודר, ומדפיסים `head()` לבדיקת תקינות.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "48741b99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Daily event counts (date x detector):\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# 3) Daily event counts per detector (exam skill: groupby + size + unstack)\n",
    "# -----------------------------\n",
    "# TODO: Create a DAILY event-count report from events_clean in a single pipeline.\n",
    "#       Use groupby([\"date\",\"detector\"]) to group events by day and detector, then .size() to count rows per group.\n",
    "#       Reshape the result into a wide table with .unstack(fill_value=0) so rows are dates, columns are detectors,\n",
    "#       and missing (date, detector) combinations become 0. Finally, sort rows by date with sort_index() and\n",
    "#       sort columns (detectors) with sort_index(axis=1). Print a short preview using head() with a clear label.\n",
    "daily_counts = (\n",
    "    \n",
    ")\n",
    "\n",
    "try:\n",
    "    print(\"\\nDaily event counts (date x detector):\")\n",
    "    print(daily_counts.head())\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74784680",
   "metadata": {},
   "source": [
    "## חלק 4 – חיבור מטא-דאטה וחישוב אנרגיה מכוילת (merge + עמודה נגזרת)\n",
    "\n",
    "בשלב הזה אנחנו עוברים מלוג גולמי לנתונים בעלי משמעות פיזיקלית יותר:\n",
    "\n",
    "- מבצעים **merge** בין טבלת האירועים הנקייה (`events_clean`) לבין טבלת המטא-דאטה של הגלאים (`detectors`), כך שלכל אירוע נצמיד את פרטי הקליברציה של הגלאי שמדד אותו (module, gain, offset).\n",
    "- לאחר החיבור מחשבים עמודה חדשה `energy` בצורה **וקטורית** (ללא לולאות):  \n",
    "  \\( E = gain \\cdot adc + offset \\)  \n",
    "  זה מדמה המרה ממדידה גולמית (ADC) ל“אנרגיה” מכוילת.\n",
    "- מוסיפים בדיקות בסיסיות (`assert`) כדי לוודא:\n",
    "  1) שלא נשארו אירועים עם גלאי שלא נמצא בטבלת המטא-דאטה  \n",
    "  2) שהאנרגיה שחושבה היא מספר סופי (לא NaN/inf)\n",
    "- לבסוף מדפיסים תצוגה מקדימה של העמודות החשובות כדי לוודא שהחיבור והחישוב הצליחו.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d056145e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 4) Merge metadata + compute calibrated energy (Week 11-ish: merge + vectorized transform)\n",
    "# -----------------------------\n",
    "# TODO: Merge the cleaned events table with the detector metadata table.\n",
    "#       Goal: for every row in events_clean, attach its detector's module/gain/offset from detectors.\n",
    "#       Use a LEFT join so we keep all events even if metadata is missing (we'll detect that later).\n",
    "#       Merge key: \"detector\" (exists in both tables).\n",
    "# events_cal = ...\n",
    "\n",
    "# TODO: Compute a calibrated \"energy\" column using a vectorized formula (no loops):\n",
    "#       energy = gain * adc + offset\n",
    "#       This simulates converting a raw ADC measurement into a calibrated physical quantity.\n",
    "# events_cal[\"energy\"] = ...\n",
    "\n",
    "# Basic sanity checks\n",
    "try:\n",
    "    assert events_cal[\"module\"].notna().all(), \"Some detectors did not match metadata!\"\n",
    "    assert np.isfinite(events_cal[\"energy\"]).all(), \"Energy contains non-finite values!\"\n",
    "\n",
    "    print(\"\\nEvents with calibration columns:\")\n",
    "    print(events_cal[[\"timestamp\", \"date\", \"detector\", \"module\", \"adc\", \"gain\", \"offset\", \"energy\"]].head())\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64dba240",
   "metadata": {},
   "source": [
    "## חלק 5 – סיכום יומי לפי מודול (Multi-Aggregation עם groupby)\n",
    "\n",
    "כאן אנחנו מסכמים את הנתונים המכיילים לרמת **מודולים** (ולא גלאים בודדים), כדי לקבל תמונת מצב תפעולית “גבוהה” יותר:\n",
    "\n",
    "- מקבצים (`groupby`) לפי `date` ו־`module`, כך שכל קבוצה מייצגת מודול מסוים ביום מסוים.\n",
    "- מתמקדים בעמודת `energy` ומפעילים עליה כמה אגרגציות במקביל בעזרת `agg`:\n",
    "  - `n_events`: כמה אירועים נמדדו (ספירה)\n",
    "  - `mean_energy`: אנרגיה ממוצעת\n",
    "  - `max_energy`: האנרגיה המקסימלית שנמדדה באותו יום במודול\n",
    "- לאחר מכן עושים `reset_index()` כדי להפוך את האינדקס לעמודות רגילות (נוח להמשך עבודה/הדפסה).\n",
    "- ממיינים לפי תאריך ואז מודול כדי לקבל טבלה קריאה ומסודרת.\n",
    "- לבסוף מציגים `head()` כדי לוודא שהמבנה והתוצאות הגיוניים.\n",
    "\n",
    "התוצאה היא טבלה בפורמט “ארוך” (long format), שמתאימה גם לניתוח נוסף וגם ליצירת טבלאות/גרפים.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "db06918a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Module daily summary (long format):\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# 5) Daily module-level summary table (multi-agg)\n",
    "# -----------------------------\n",
    "# TODO: Build a daily, module-level summary table from the calibrated events data:\n",
    "#       use the date and module columns to define groups, then summarize the calibrated measurements\n",
    "#       within each group using multiple statistics (so the output has several informative columns).\n",
    "#       After aggregating, convert the grouped result into a regular DataFrame, sort it in a consistent\n",
    "#       report-friendly order, and print a small preview to confirm the structure and values look right.\n",
    "module_daily_summary = (\n",
    "\n",
    ")\n",
    "\n",
    "try:\n",
    "    print(\"\\nModule daily summary (long format):\")\n",
    "    print(module_daily_summary.head())\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1ccd13",
   "metadata": {},
   "source": [
    "## מעבר מפורמט “ארוך” לדוח “רחב” לפי מודולים\n",
    "\n",
    "לאחר שיש לנו טבלת סיכום יומית בפורמט ארוך (`module_daily_summary`), אנחנו ממירים אותה לטבלת דוח רחבה ונוחה לקריאה:\n",
    "- השורות הן תאריכים\n",
    "- העמודות הן מודולים\n",
    "- בכל תא מופיע הערך הממוצע היומי (למשל mean energy) עבור אותו מודול\n",
    "\n",
    "ההמרה נעשית עם `pivot_table`, ואז ממיינים את התאריכים ואת שמות המודולים כדי לקבל פלט עקבי ומסודר. לבסוף מדפיסים `head()` כדי לוודא שהמבנה תקין."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5731ef8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean energy per module (wide):\n"
     ]
    }
   ],
   "source": [
    "# TODO: Create a wide, report-style table from module_daily_summary:\n",
    "#       reshape the data so each row is a date and each column is a module, with cells showing the\n",
    "#       (daily) average calibrated measurement for that module. Use a pivot-style operation to go\n",
    "#       from the long format summary to a wide format report, then sort the date index chronologically\n",
    "#       and sort the module columns consistently. Finally, print a short preview (head) to confirm\n",
    "#       the output layout is \"date x module\" and the values look reasonable.\n",
    "\n",
    "# Also make a wide \"report\" view: date x module (mean energy)\n",
    "# module_mean_energy_wide = module_daily_summary.pivot_table(\n",
    "# \n",
    "# )\n",
    "\n",
    "try:\n",
    "    print(\"\\nMean energy per module (wide):\")\n",
    "    print(module_mean_energy_wide.head())\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2abb7fdb",
   "metadata": {},
   "source": [
    "## חלק 6 – מעבר לפורמט “ארוך” לצורך גרפים (melt)\n",
    "\n",
    "כאן אנחנו ממירים טבלאות דוח “רחבות” (wide) לפורמט “ארוך” (long) שמתאים יותר לשרטוטים ולעבודה עם ספריות גרפים:\n",
    "\n",
    "- `daily_counts` היה בפורמט שבו כל עמודה היא גלאי. בעזרת `reset_index()` ו־`melt` הופכים אותו לטבלה עם שלוש עמודות מרכזיות: תאריך, גלאי, וספירת אירועים.\n",
    "- `daily_mean_temp` היה בפורמט שבו כל עמודה היא פרוב. באותו אופן, `melt` יוצר טבלה עם תאריך, פרוב, וטמפרטורה ממוצעת.\n",
    "\n",
    "בפורמט הארוך כל שורה מייצגת תצפית אחת (תאריך + חיישן), מה שמקל לייצר גרפים כמו קווים/נקודות לפי קטגוריה.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "724b5cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Convert the daily_counts wide report into a long/tidy table for plotting.\n",
    "#       Goal: one row per (date, detector) with a single count value column.\n",
    "#       Steps: move \"date\" out of the index (reset_index), then melt detector columns into two columns:\n",
    "#       - a categorical column for detector IDs\n",
    "#       - a numeric column for the event counts\n",
    "counts_long = ...\n",
    "\n",
    "# TODO: Convert the daily_mean_temp wide report into a long/tidy table for plotting.\n",
    "#       Goal: one row per (date, probe) with a single mean temperature value column.\n",
    "#       Steps: reset_index to expose \"date\", then melt probe columns into:\n",
    "#       - a categorical column for probe IDs\n",
    "#       - a numeric column for mean temperature values\n",
    "temps_long = ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61208ea1",
   "metadata": {},
   "source": [
    "## סיכום – הכנת הנתונים להצגה וסקירה ויזואלית של התוצאות\n",
    "\n",
    "בחלק המסכם הזה אנחנו עוברים משלב עיבוד הנתונים לשלב **ההצגה והבדיקה**:\n",
    "\n",
    "ראשית, טבלאות הדוח הרחבות מומרות לפורמט “ארוך” (`melt`). זהו פורמט סטנדרטי ונוח לויזואליזציה ולניתוחים המשכיים, שבו כל שורה מייצגת תצפית אחת (תאריך + חיישן/גלאי/מודול).\n",
    "\n",
    "לאחר מכן מצוירים גרפים פשוטים באמצעות Pandas ו־Matplotlib, שמאפשרים לקבל במהירות תמונת מצב:\n",
    "- כיצד מספר האירועים משתנה מיום ליום בכל גלאי\n",
    "- כיצד הטמפרטורה הממוצעת משתנה בפרובים השונים\n",
    "- כיצד האנרגיה הממוצעת (המכוילת) משתנה בין מודולים לאורך הזמן\n",
    "\n",
    "לבסוף, כל תוצרי הביניים והדוחות הסופיים נאספים למילון אחד (`report`). זה מדמה שלב סיום של ניתוח ניסויי: ריכוז כל הטבלאות הרלוונטיות במקום אחד לצורך בדיקות, המשך עיבוד או הגשה כדוח.\n",
    "\n",
    "קטע זה משלים את ה־Workflow המלא: מנתונים גולמיים ורועשים → ניקוי ועיבוד → סיכום יומי → הצגה ויזואלית ותוצר סופי.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7d39c357",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Plot A: Daily counts by detector\n",
    "    ax = daily_counts.plot(kind=\"line\", marker=\"o\", figsize=(10, 4))\n",
    "    ax.set_title(\"Daily event counts per detector\")\n",
    "    ax.set_xlabel(\"Date\")\n",
    "    ax.set_ylabel(\"Count\")\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Plot B: Daily mean temperature per probe\n",
    "    ax = daily_mean_temp.plot(kind=\"line\", marker=\"o\", figsize=(10, 4))\n",
    "    ax.set_title(\"Daily mean temperature per probe\")\n",
    "    ax.set_xlabel(\"Date\")\n",
    "    ax.set_ylabel(\"Temperature (°C)\")\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Plot C: Mean calibrated energy per module\n",
    "    ax = module_mean_energy_wide.plot(kind=\"line\", marker=\"o\", figsize=(10, 4))\n",
    "    ax.set_title(\"Daily mean calibrated energy per module\")\n",
    "    ax.set_xlabel(\"Date\")\n",
    "    ax.set_ylabel(\"Mean energy (arb. units)\")\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    report = {\n",
    "        \"daily_mean_temp\": daily_mean_temp,\n",
    "        \"daily_counts\": daily_counts,\n",
    "        \"module_daily_summary_long\": module_daily_summary,\n",
    "        \"module_mean_energy_wide\": module_mean_energy_wide,\n",
    "        \"counts_long\": counts_long,\n",
    "        \"temps_long\": temps_long,\n",
    "    }\n",
    "\n",
    "    print(\"\\nReport keys:\", list(report.keys()))\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846359af",
   "metadata": {},
   "source": [
    "`````{admonition} Solutions\n",
    ":class: dropdown, tip\n",
    "```python\n",
    "# Physics-inspired Pandas notebook (FULL SOLUTION CODE)\n",
    "# Problem 1: \"Detector Array Daily Operations Report\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# -----------------------------\n",
    "# 0) Generate synthetic-but-realistic data (raw, slightly messy)\n",
    "# -----------------------------\n",
    "rng = np.random.default_rng(42)\n",
    "\n",
    "# Detector metadata / calibration\n",
    "detectors = pd.DataFrame({\n",
    "    \"detector\": [f\"D{i}\" for i in range(1, 7)],\n",
    "    \"module\":   [\"M1\", \"M1\", \"M2\", \"M2\", \"M3\", \"M3\"],\n",
    "    \"gain\":     rng.uniform(0.8, 1.4, size=6),\n",
    "    \"offset\":   rng.uniform(-5.0, 5.0, size=6),\n",
    "})\n",
    "\n",
    "# Create a time range spanning multiple days, but events are irregular\n",
    "start = pd.Timestamp(\"2025-12-20 00:00:00\")\n",
    "end   = pd.Timestamp(\"2025-12-26 23:59:59\")\n",
    "total_seconds = int((end - start).total_seconds())\n",
    "\n",
    "n_events = 3500\n",
    "event_times = start + pd.to_timedelta(rng.integers(0, total_seconds, size=n_events), unit=\"s\")\n",
    "event_times = pd.Series(event_times).sample(frac=1, random_state=0).reset_index(drop=True)  # shuffled\n",
    "\n",
    "events = pd.DataFrame({\n",
    "    \"timestamp\": event_times.astype(str),  # stored as strings in raw logs\n",
    "    \"detector\": rng.choice(detectors[\"detector\"], size=n_events, replace=True),\n",
    "    \"adc\": rng.gamma(shape=4.0, scale=35.0, size=n_events) + rng.normal(0, 3, size=n_events),\n",
    "})\n",
    "\n",
    "# Add some deliberately invalid timestamps and a couple junk rows\n",
    "bad_idx = rng.choice(events.index, size=25, replace=False)\n",
    "events.loc[bad_idx, \"timestamp\"] = rng.choice(\n",
    "    [\"not_a_time\", \"2025-13-99 99:99:99\", \"\", \"2025/12/25 25:61:00\"],\n",
    "    size=len(bad_idx),\n",
    ")\n",
    "# Also introduce some missing adc values\n",
    "events.loc[rng.choice(events.index, size=15, replace=False), \"adc\"] = np.nan\n",
    "\n",
    "# Temperature probe logs (more regular, but still messy)\n",
    "probes = [\"T1\", \"T2\", \"T3\"]\n",
    "n_temps = 1400\n",
    "temp_times = start + pd.to_timedelta(rng.integers(0, total_seconds, size=n_temps), unit=\"s\")\n",
    "\n",
    "temps = pd.DataFrame({\n",
    "    \"timestamp\": pd.Series(temp_times).astype(str),\n",
    "    \"probe\": rng.choice(probes, size=n_temps, replace=True),\n",
    "    \"temp_C\": rng.normal(loc=24.0, scale=1.7, size=n_temps),\n",
    "})\n",
    "\n",
    "# Add a few invalid timestamps and missing temps\n",
    "bad_idx_t = rng.choice(temps.index, size=12, replace=False)\n",
    "temps.loc[bad_idx_t, \"timestamp\"] = rng.choice([\"bad\", \"2025-12-XX 12:00:00\", \"\"], size=len(bad_idx_t))\n",
    "temps.loc[rng.choice(temps.index, size=10, replace=False), \"temp_C\"] = np.nan\n",
    "\n",
    "print(\"Raw shapes:\")\n",
    "print(\"  detectors:\", detectors.shape)\n",
    "print(\"  events:\", events.shape)\n",
    "print(\"  temps:\", temps.shape)\n",
    "\n",
    "# -----------------------------\n",
    "# 1) Clean + parse timestamps (core exam skill: pd.to_datetime, errors='coerce')\n",
    "# -----------------------------\n",
    "events_clean = events.copy()\n",
    "events_clean[\"timestamp\"] = pd.to_datetime(events_clean[\"timestamp\"], errors=\"coerce\")\n",
    "events_clean = events_clean.dropna(subset=[\"timestamp\"])  # remove invalid timestamps\n",
    "events_clean = events_clean.dropna(subset=[\"adc\"])        # remove missing adc\n",
    "events_clean[\"date\"] = events_clean[\"timestamp\"].dt.date  # daily rollup key\n",
    "\n",
    "temps_clean = temps.copy()\n",
    "temps_clean[\"timestamp\"] = pd.to_datetime(temps_clean[\"timestamp\"], errors=\"coerce\")\n",
    "temps_clean = temps_clean.dropna(subset=[\"timestamp\"])\n",
    "temps_clean = temps_clean.dropna(subset=[\"temp_C\"])\n",
    "temps_clean[\"date\"] = temps_clean[\"timestamp\"].dt.date\n",
    "\n",
    "print(\"\\nAfter cleaning:\")\n",
    "print(\"  events_clean:\", events_clean.shape)\n",
    "print(\"  temps_clean:\", temps_clean.shape)\n",
    "\n",
    "# -----------------------------\n",
    "# 2) Daily mean temperature per probe (exam skill: pivot_table)\n",
    "# -----------------------------\n",
    "daily_mean_temp = temps_clean.pivot_table(\n",
    "    index=\"date\",\n",
    "    columns=\"probe\",\n",
    "    values=\"temp_C\",\n",
    "    aggfunc=\"mean\"\n",
    ").sort_index().sort_index(axis=1)\n",
    "\n",
    "print(\"\\nDaily mean temperature (date x probe):\")\n",
    "print(daily_mean_temp.head())\n",
    "\n",
    "# -----------------------------\n",
    "# 3) Daily event counts per detector (exam skill: groupby + size + unstack)\n",
    "# -----------------------------\n",
    "daily_counts = (\n",
    "    events_clean\n",
    "    .groupby([\"date\", \"detector\"])\n",
    "    .size()\n",
    "    .unstack(fill_value=0)\n",
    "    .sort_index()\n",
    "    .sort_index(axis=1)\n",
    ")\n",
    "\n",
    "print(\"\\nDaily event counts (date x detector):\")\n",
    "print(daily_counts.head())\n",
    "\n",
    "# -----------------------------\n",
    "# 4) Merge metadata + compute calibrated energy (Week 11-ish: merge + vectorized transform)\n",
    "# -----------------------------\n",
    "events_cal = events_clean.merge(detectors, on=\"detector\", how=\"left\")\n",
    "\n",
    "# Calibrated energy proxy: E = gain*adc + offset\n",
    "events_cal[\"energy\"] = events_cal[\"gain\"] * events_cal[\"adc\"] + events_cal[\"offset\"]\n",
    "\n",
    "# Basic sanity checks\n",
    "assert events_cal[\"module\"].notna().all(), \"Some detectors did not match metadata!\"\n",
    "assert np.isfinite(events_cal[\"energy\"]).all(), \"Energy contains non-finite values!\"\n",
    "\n",
    "print(\"\\nEvents with calibration columns:\")\n",
    "print(events_cal[[\"timestamp\", \"date\", \"detector\", \"module\", \"adc\", \"gain\", \"offset\", \"energy\"]].head())\n",
    "\n",
    "# -----------------------------\n",
    "# 5) Daily module-level summary table (multi-agg)\n",
    "# -----------------------------\n",
    "module_daily_summary = (\n",
    "    events_cal\n",
    "    .groupby([\"date\", \"module\"])[\"energy\"]\n",
    "    .agg(\n",
    "        n_events=\"size\",\n",
    "        mean_energy=\"mean\",\n",
    "        max_energy=\"max\"\n",
    "    )\n",
    "    .reset_index()\n",
    "    .sort_values([\"date\", \"module\"])\n",
    ")\n",
    "\n",
    "print(\"\\nModule daily summary (long format):\")\n",
    "print(module_daily_summary.head())\n",
    "\n",
    "# Also make a wide \"report\" view: date x module (mean energy)\n",
    "module_mean_energy_wide = module_daily_summary.pivot_table(\n",
    "    index=\"date\", columns=\"module\", values=\"mean_energy\", aggfunc=\"mean\"\n",
    ").sort_index().sort_index(axis=1)\n",
    "\n",
    "print(\"\\nMean energy per module (wide):\")\n",
    "print(module_mean_energy_wide.head())\n",
    "\n",
    "# -----------------------------\n",
    "# 6) Reshaping for plotting: melt\n",
    "# -----------------------------\n",
    "counts_long = daily_counts.reset_index().melt(\n",
    "    id_vars=\"date\",\n",
    "    var_name=\"detector\",\n",
    "    value_name=\"n_events\"\n",
    ")\n",
    "\n",
    "temps_long = daily_mean_temp.reset_index().melt(\n",
    "    id_vars=\"date\",\n",
    "    var_name=\"probe\",\n",
    "    value_name=\"mean_temp_C\"\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# 7) Quick plots (pandas/matplotlib)\n",
    "# -----------------------------\n",
    "# Plot A: Daily counts by detector\n",
    "ax = daily_counts.plot(kind=\"line\", marker=\"o\", figsize=(10, 4))\n",
    "ax.set_title(\"Daily event counts per detector\")\n",
    "ax.set_xlabel(\"Date\")\n",
    "ax.set_ylabel(\"Count\")\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot B: Daily mean temperature per probe\n",
    "ax = daily_mean_temp.plot(kind=\"line\", marker=\"o\", figsize=(10, 4))\n",
    "ax.set_title(\"Daily mean temperature per probe\")\n",
    "ax.set_xlabel(\"Date\")\n",
    "ax.set_ylabel(\"Temperature (°C)\")\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot C: Mean calibrated energy per module\n",
    "ax = module_mean_energy_wide.plot(kind=\"line\", marker=\"o\", figsize=(10, 4))\n",
    "ax.set_title(\"Daily mean calibrated energy per module\")\n",
    "ax.set_xlabel(\"Date\")\n",
    "ax.set_ylabel(\"Mean energy (arb. units)\")\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# -----------------------------\n",
    "# 8) Final \"Report\" objects students would submit\n",
    "# -----------------------------\n",
    "report = {\n",
    "    \"daily_mean_temp\": daily_mean_temp,\n",
    "    \"daily_counts\": daily_counts,\n",
    "    \"module_daily_summary_long\": module_daily_summary,\n",
    "    \"module_mean_energy_wide\": module_mean_energy_wide,\n",
    "    \"counts_long\": counts_long,\n",
    "    \"temps_long\": temps_long,\n",
    "}\n",
    "\n",
    "print(\"\\nReport keys:\", list(report.keys()))\n",
    "```\n",
    "`````"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
